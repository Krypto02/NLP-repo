{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7191a6a",
   "metadata": {},
   "source": [
    "\n",
    "## Environment Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fadf686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
      "0      1.jpg           0        0           0                0         0   \n",
      "1     10.jpg           1        0           0                0         1   \n",
      "2   1000.jpg           0        0           0                0         0   \n",
      "3  10000.jpg           0        0           0                0         0   \n",
      "4  10006.jpg           0        0           0                0         0   \n",
      "\n",
      "                                                Text  \n",
      "0                                      Milk Milk.zip  \n",
      "1  ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...  \n",
      "2  BREAKING NEWS: Russia releases photo of DONALD...  \n",
      "3                       MAN SEEKING WOMAN Ignad 18 O  \n",
      "4  Me explaining the deep lore of. J.R.R. Tolkein...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/training.csv\", sep=\"\\t\", header=0)\n",
    "fixed_cols = [\"file_name\", \"misogynous\", \"shaming\", \"stereotype\", \"objectification\", \"violence\"]\n",
    "text_cols = df.columns[len(fixed_cols):]\n",
    "df[\"Text\"] = df[text_cols].astype(str).agg(\" \".join, axis=1)\n",
    "df = df[fixed_cols + [\"Text\"]]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6fc40c",
   "metadata": {},
   "source": [
    "### Explanation: Data Loading and Preparation\n",
    "\n",
    "**What does this cell do?**\n",
    "\n",
    "1. Loads the dataset from `../data/training.csv` (located in the data/ directory)\n",
    "2. Extracts fixed columns: file name, classification labels (misogynous, shaming, stereotype, objectification, violence)\n",
    "3. Combines text columns: concatenates all text columns into a single \"Text\" column\n",
    "4. Reorganizes the dataframe to contain only necessary columns\n",
    "\n",
    "**Dataset structure:**\n",
    "- `file_name`: image file name of the meme\n",
    "- `misogynous`: binary label (0 = non-misogynous, 1 = misogynous) - our target variable\n",
    "- `shaming`, `stereotype`, `objectification`, `violence`: other classification categories\n",
    "- `Text`: complete concatenated meme text\n",
    "\n",
    "**Actual results:**\n",
    "\n",
    "The dataset contains multiple meme examples. The first 5 records show:\n",
    "\n",
    "| file_name | misogynous | Text (excerpt) |\n",
    "|-----------|------------|----------------|\n",
    "| 1.jpg     | 0          | Milk Milk.zip   |\n",
    "| 10.jpg    | 1          | ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S... |\n",
    "| 1000.jpg  | 0          | BREAKING NEWS: Russia releases photo of DONALD... |\n",
    "| 10000.jpg | 0          | MAN SEEKING WOMAN Ignad 18 O |\n",
    "| 10006.jpg | 0          | Me explaining the deep lore of. J.R.R. Tolkein... |\n",
    "\n",
    "The dataset contains a mixture of misogynous (1) and non-misogynous (0) content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664ede14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 6000 (requirement: min 5,000)\n",
      "Test samples: 1500 (requirement: min 1,000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "767     COUGARS The young may have the energy, It's no...\n",
       "5581    DID YOU HEAR ABOUT THE DEPRESSED SEWER WORKER ...\n",
       "4431    Those girls that think we don't know they use ...\n",
       "7381    We have no cow in the farm. Where's all this m...\n",
       "1218    BRONE My housemates are convinced our house is...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "nExamples = 7500\n",
    "X = df[\"Text\"].iloc[:nExamples]\n",
    "y = df[\"misogynous\"].iloc[:nExamples]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print(f\"Train samples: {len(X_train)} (requirement: min 5,000)\")\n",
    "print(f\"Test samples: {len(X_test)} (requirement: min 1,000)\")\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a45a19",
   "metadata": {},
   "source": [
    "### Explanation: Train/Test Data Split\n",
    "\n",
    "**What does this cell do?**\n",
    "\n",
    "1. Imports necessary libraries for machine learning (sklearn)\n",
    "2. Sets random seed (RANDOM_STATE = 42) for reproducibility\n",
    "3. Selects a subset of 7,500 examples from the complete dataset\n",
    "4. Separates features (X) and labels (y):\n",
    "   - `X`: \"Text\" column (the meme text)\n",
    "   - `y`: \"misogynous\" column (0 or 1)\n",
    "5. Splits the data into training (80%) and test (20%) using `train_test_split`\n",
    "   - `stratify=y`: maintains the same class proportion in both sets\n",
    "\n",
    "**Why is stratified splitting important?**\n",
    "\n",
    "If the dataset has 60% class 0 and 40% class 1, stratified splitting ensures that both training and test sets maintain approximately the same proportion (60/40). This prevents one set from having too many examples of one class.\n",
    "\n",
    "**Actual results:**\n",
    "\n",
    "- **Train samples: 6,000** (meets minimum requirement of 5,000)\n",
    "- **Test samples: 1,500** (meets minimum requirement of 1,000)\n",
    "\n",
    "**Training set examples:**\n",
    "\n",
    "```\n",
    "767     COUGARS The young may have the energy, It's no...\n",
    "5581    DID YOU HEAR ABOUT THE DEPRESSED SEWER WORKER ...\n",
    "4431    Those girls that think we don't know they use ...\n",
    "7381    We have no cow in the farm. Where's all this m...\n",
    "1218    BRONE My housemates are convinced our house is...\n",
    "```\n",
    "\n",
    "The indices are randomized due to automatic shuffling in `train_test_split`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a7bd8",
   "metadata": {},
   "source": [
    "## Manual TF-IDF Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20edd72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TF-IDF Manual + Logistic Regression ===\n",
      "TF-IDF shape: (6000, 21079)\n",
      "Best params: {'C': 1}\n",
      "F1-Macro (TF-IDF): 0.7785\n",
      "\n",
      "=== Averaged Word Embeddings Manual + Logistic Regression ===\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TF-IDF Manual + Logistic Regression ===\")\n",
    "from collections import Counter\n",
    "import math\n",
    "def build_vocabulary(texts):\n",
    "    \"\"\"Build vocabulary efficiently\"\"\"\n",
    "    vocab = set()\n",
    "    for text in texts:\n",
    "        vocab.update(text.lower().split())\n",
    "    return {word: idx for idx, word in enumerate(sorted(vocab))}\n",
    "def compute_tfidf_manual_sparse(texts, vocab):\n",
    "    \"\"\"Use sparse structure (dict de dicts) para eficiencia\"\"\"\n",
    "    n_docs = len(texts)\n",
    "    word_doc_count = Counter()\n",
    "    for text in texts:\n",
    "        unique_words = set(text.lower().split())\n",
    "        word_doc_count.update(unique_words)\n",
    "    idf = {word: math.log(n_docs / (1 + word_doc_count[word])) for word in vocab}\n",
    "    tfidf_sparse = []\n",
    "    for text in texts:\n",
    "        words = text.lower().split()\n",
    "        word_counts = Counter(words)\n",
    "        doc_tfidf = {}\n",
    "        for word, count in word_counts.items():\n",
    "            if word in vocab:\n",
    "                word_idx = vocab[word]\n",
    "                tf = count / len(words)\n",
    "                tfidf_val = tf * idf[word]\n",
    "                doc_tfidf[word_idx] = tfidf_val\n",
    "        tfidf_sparse.append(doc_tfidf)\n",
    "    return tfidf_sparse\n",
    "def get_numpied(tfidf_sparse, n_features):\n",
    "    \"\"\"Convert tfidf result from python to numpy\"\"\"\n",
    "    n_docs = len(tfidf_sparse)\n",
    "    dense = np.zeros((n_docs, n_features))\n",
    "    for doc_idx, doc_dict in enumerate(tfidf_sparse):\n",
    "        for word_idx, val in doc_dict.items():\n",
    "            dense[doc_idx, word_idx] = val\n",
    "    return dense\n",
    "vocab = build_vocabulary(X_train)\n",
    "X_train_tfidf_sparse = compute_tfidf_manual_sparse(X_train, vocab)\n",
    "X_test_tfidf_sparse = compute_tfidf_manual_sparse(X_test, vocab)\n",
    "X_train_tfidf = get_numpied(X_train_tfidf_sparse, len(vocab))\n",
    "X_test_tfidf = get_numpied(X_test_tfidf_sparse, len(vocab))\n",
    "print(f\"TF-IDF shape: {X_train_tfidf.shape}\")\n",
    "lr = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "param_grid = {'C': [0.1, 1, 10]}\n",
    "grid = GridSearchCV(lr, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "print(f\"Best params: {grid.best_params_}\")\n",
    "y_pred_tfidf = grid.predict(X_test_tfidf)\n",
    "print(f\"F1-Macro (TF-IDF): {f1_score(y_test, y_pred_tfidf, average='macro'):.4f}\")\n",
    "print(\"\\n=== Averaged Word Embeddings Manual + Logistic Regression ===\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38162bbf",
   "metadata": {},
   "source": [
    "### Explanation: Manual TF-IDF Implementation\n",
    "\n",
    "**What does this cell do?**\n",
    "\n",
    "This cell implements **TF-IDF from scratch** without using high-level libraries, to understand how it works internally.\n",
    "\n",
    "#### **Step 1: Build vocabulary**\n",
    "```python\n",
    "def build_vocabulary(texts):\n",
    "```\n",
    "Iterates through all training texts and creates a dictionary mapping each unique word to a numeric index.\n",
    "- Example: `{\"hello\": 0, \"world\": 1, \"meme\": 2, ...}`\n",
    "\n",
    "#### **Step 2: Compute TF-IDF**\n",
    "```python\n",
    "def compute_tfidf_manual_sparse(texts, vocab):\n",
    "```\n",
    "\n",
    "**TF-IDF = Term Frequency × Inverse Document Frequency**\n",
    "\n",
    "**TF (Term Frequency)**: Relative frequency of a word in a document\n",
    "$$TF(t, d) = \\frac{\\text{occurrences of } t \\text{ in } d}{\\text{total words in } d}$$\n",
    "\n",
    "**IDF (Inverse Document Frequency)**: Penalizes common words, rewards specific words\n",
    "$$IDF(t) = \\log\\left(\\frac{\\text{total documents}}{\\text{documents containing } t + 1}\\right)$$\n",
    "\n",
    "**Practical example:**\n",
    "- Document: \"woman in kitchen woman cooking\"\n",
    "- Total words: 5\n",
    "- \"woman\" appears 2 times → TF = 2/5 = 0.4\n",
    "- If \"woman\" appears in 500 of 6000 documents → IDF = log(6000/501) ≈ 2.48\n",
    "- **TF-IDF(\"woman\") = 0.4 × 2.48 = 0.992**\n",
    "\n",
    "If \"the\" appears in all documents → IDF ≈ 0 → TF-IDF ≈ 0 (non-discriminative word)\n",
    "\n",
    "#### **Step 3: Convert to NumPy matrix**\n",
    "```python\n",
    "def get_numpied(tfidf_sparse, n_features):\n",
    "```\n",
    "Converts the sparse format (dictionaries) to a dense NumPy matrix for use with sklearn.\n",
    "\n",
    "#### **Step 4: Model training**\n",
    "- Uses **Logistic Regression** as classifier\n",
    "- **GridSearchCV** searches for the best C value (regularization parameter)\n",
    "  - `C = 0.1`: high regularization (simple model)\n",
    "  - `C = 1`: balanced regularization\n",
    "  - `C = 10`: low regularization (complex model)\n",
    "- **5-fold cross-validation**: divides training into 5 parts, trains on 4 and validates on 1, rotating\n",
    "- **F1-macro metric**: average F1-score of both classes (non-misogynous and misogynous)\n",
    "\n",
    "**Actual results:**\n",
    "\n",
    "- **TF-IDF shape: (6000, 21079)**\n",
    "  - 6,000 documents (tweets/memes)\n",
    "  - 21,079 unique words in vocabulary\n",
    "  \n",
    "- **Best params: {'C': 1}**\n",
    "  - Best regularization value is C=1 (balance between complexity and generalization)\n",
    "  \n",
    "- **F1-Macro (TF-IDF): 0.7785**\n",
    "  - **77.85% average precision** across both classes\n",
    "  - Good performance given the problem complexity\n",
    "\n",
    "** Interpretation:**\n",
    "TF-IDF captures well the importance of specific words. Words like \"bitch\", \"whore\", \"kitchen\" will have high TF-IDF values in misogynous documents, while common words like \"the\", \"is\", \"a\" will have values close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e3e41",
   "metadata": {},
   "source": [
    "## Imported TF-IDF Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d437b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TF-IDF + Logistic Regression ===\n",
      "TF-IDF shape: (6000, 5000)\n",
      "Best params: {'C': 1}\n",
      "F1-Macro (TF-IDF): 0.7840\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TF-IDF + Logistic Regression ===\")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# -----------------------------\n",
    "# 1️TF-IDF Vectorization\n",
    "# -----------------------------\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 1),\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF shape: {X_train_tfidf.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2️Logistic Regression + Grid Search\n",
    "# -----------------------------\n",
    "\n",
    "lr = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10]}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    lr,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(f\"Best params: {grid.best_params_}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3️Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "y_pred_tfidf = grid.predict(X_test_tfidf)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_tfidf, average='macro')\n",
    "\n",
    "print(f\"F1-Macro (TF-IDF): {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218e463",
   "metadata": {},
   "source": [
    "### Explanation: TF-IDF with scikit-learn (Optimized Implementation)\n",
    "\n",
    "**What does this cell do?**\n",
    "\n",
    "This cell repeats the TF-IDF process but using the **optimized scikit-learn implementation** (`TfidfVectorizer`) instead of manual code.\n",
    "\n",
    "#### **Step 1: TF-IDF Vectorization**\n",
    "```python\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,      # Limits to 5,000 most frequent words\n",
    "    ngram_range=(1, 1),     # Only unigrams (individual words)\n",
    "    lowercase=True          # Converts everything to lowercase\n",
    ")\n",
    "```\n",
    "\n",
    "**Important parameters:**\n",
    "- **max_features=5000**: Instead of using all 21,079 unique words, only uses the 5,000 most frequent\n",
    "  - **Advantage**: Reduces dimensionality, eliminates very rare words that can be noise\n",
    "  - **Disadvantage**: Could lose information from rare but discriminative words\n",
    "  \n",
    "- **ngram_range=(1,1)**: Only considers individual words\n",
    "  - \"woman\" → individual feature\n",
    "  - Does NOT consider \"woman kitchen\" as a bigram\n",
    "\n",
    "- **lowercase=True**: Normalizes text\n",
    "  - \"Woman\", \"WOMAN\", \"woman\" → all treated equally\n",
    "\n",
    "#### **Step 2: Transformation**\n",
    "```python\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "```\n",
    "\n",
    "- **fit_transform**: Learns vocabulary from training set AND transforms\n",
    "- **transform**: Only transforms using already learned vocabulary (does NOT learn from test, avoids data leakage)\n",
    "\n",
    "#### **Step 3: Grid Search**\n",
    "Same as manual implementation, searches for best C value using 5-fold cross-validation.\n",
    "\n",
    "**Actual results:**\n",
    "\n",
    "- **TF-IDF shape: (6000, 5000)**\n",
    "  - Reduction from 21,079 → 5,000 features\n",
    "  - **76.3% dimensional reduction**\n",
    "  \n",
    "- **Best params: {'C': 1}**\n",
    "  - Same result as manual implementation\n",
    "  \n",
    "- **F1-Macro (TF-IDF): 0.7840**\n",
    "  - **78.40% precision**\n",
    "  - **+0.55% better than manual implementation (0.7785)**\n",
    "\n",
    "**Why does it work better with fewer features?**\n",
    "\n",
    "1. **Reduces overfitting**: 21,079 features can lead to memorizing noise\n",
    "2. **Eliminates rare words**: words appearing 1-2 times are usually typos or irrelevant\n",
    "3. **Improves generalization**: model focuses on consistent patterns\n",
    "\n",
    "**Conclusion:** sklearn implementation is more efficient and limiting to 5,000 features slightly improves performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7741a3",
   "metadata": {},
   "source": [
    "## Imported TF-IDF FastText Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab69773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FastText + Logistic Regression ===\n",
      "FastText shape: (6000, 100)\n",
      "Best params: {'C': 0.1}\n",
      "F1-Macro (FastText): 0.3357\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FastText + Logistic Regression ===\")\n",
    "\n",
    "import fasttext\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# 1️Prepare training file for FastText\n",
    "# -----------------------------\n",
    "\n",
    "# FastText requires a text file for unsupervised training\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", delete=False, encoding='utf-8') as tmp:\n",
    "    for text in X_train:\n",
    "        tmp.write(text.lower() + \"\\n\")\n",
    "    train_file_path = tmp.name\n",
    "\n",
    "# -----------------------------\n",
    "# Train FastText model\n",
    "# -----------------------------\n",
    "\n",
    "ft_model = fasttext.train_unsupervised(\n",
    "    train_file_path,\n",
    "    model='skipgram',      \n",
    "    dim=100,              \n",
    "    ws=5,                  \n",
    "    minCount=1,\n",
    "    epoch=5,\n",
    "    thread=4\n",
    ")\n",
    "\n",
    "os.remove(train_file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 3️Get document embeddings\n",
    "# -----------------------------\n",
    "\n",
    "def get_fasttext_embeddings(texts, model):\n",
    "    embeddings = np.zeros((len(texts), model.get_dimension()))\n",
    "    for i, text in enumerate(texts):\n",
    "        embeddings[i] = model.get_sentence_vector(text.lower())\n",
    "    return embeddings\n",
    "\n",
    "X_train_ft = get_fasttext_embeddings(X_train, ft_model)\n",
    "X_test_ft = get_fasttext_embeddings(X_test, ft_model)\n",
    "\n",
    "print(f\"FastText shape: {X_train_ft.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Logistic Regression (same as TF-IDF)\n",
    "# -----------------------------\n",
    "\n",
    "grid_ft = GridSearchCV(\n",
    "    LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_ft.fit(X_train_ft, y_train)\n",
    "print(f\"Best params: {grid_ft.best_params_}\")\n",
    "\n",
    "y_pred_ft = grid_ft.predict(X_test_ft)\n",
    "f1_ft = f1_score(y_test, y_pred_ft, average='macro')\n",
    "\n",
    "print(f\"F1-Macro (FastText): {f1_ft:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec0dae7",
   "metadata": {},
   "source": [
    "### EXTENSIVE Explanation: FastText - Dense Word Embeddings\n",
    "\n",
    "**What is FastText and how does it differ from TF-IDF?**\n",
    "\n",
    "FastText is a **word embeddings** model (dense vector representations of words) developed by Facebook AI Research. Unlike TF-IDF which creates sparse vectors based on frequencies, FastText learns semantic representations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Fundamental Comparison: TF-IDF vs FastText**\n",
    "\n",
    "| Feature | TF-IDF | FastText |\n",
    "|---------|--------|----------|\n",
    "| **Representation type** | Sparse | Dense |\n",
    "| **Dimensionality** | High (5,000-50,000) | Low (50-300) |\n",
    "| **Values** | Mostly zeros | All non-zero values |\n",
    "| **Vector example** | [0, 0, 0.5, 0, 0, 0, 0.8, ...] with 4,950 zeros | [0.23, -0.15, 0.67, 0.42, -0.89, ...] 100 values |\n",
    "| **Semantics** | Does not capture meaning | Captures semantic relationships |\n",
    "| **\"king\" vs \"queen\"** | Completely independent | Vectors close in space |\n",
    "| **\"dog\" vs \"cat\"** | Independent | Close (both animals) |\n",
    "| **New words** | Cannot represent them | Uses subword information |\n",
    "\n",
    "---\n",
    "\n",
    "#### **How does FastText work?**\n",
    "\n",
    "**1. Skip-gram Model**\n",
    "\n",
    "FastText uses the **skip-gram** model to learn embeddings. The goal is:\n",
    "\n",
    "> \"Given a target word, predict the context words surrounding it\"\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Sentence: \"Women belong in the kitchen\"\n",
    "Target word: \"belong\"\n",
    "Context window (ws=2): [\"Women\", \"in\"]\n",
    "```\n",
    "\n",
    "The model learns to adjust the vector of \"belong\" to be good at predicting \"Women\" and \"in\".\n",
    "\n",
    "**Mathematically:**\n",
    "$$P(w_{context} | w_{target}) = \\frac{e^{v_{context} \\cdot v_{target}}}{\\sum_{w'} e^{v_{w'} \\cdot v_{target}}}$$\n",
    "\n",
    "Words appearing in similar contexts will have similar vectors.\n",
    "\n",
    "**2. Subword Information (Character n-grams)**\n",
    "\n",
    "Unlike Word2Vec, FastText decomposes words into **character n-grams**:\n",
    "\n",
    "```\n",
    "Word: \"cooking\"\n",
    "Trigrams: <co, coo, ook, oki, kin, ing, ng>\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- Handles **typos**: \"cookin\" and \"cooking\" share many n-grams\n",
    "- Handles **rare words**: \"supermodel\" can be understood from \"super\" + \"model\"\n",
    "- Handles **morphology**: \"cook\", \"cooking\", \"cooked\" share root\n",
    "\n",
    "**Final vector of a word** = sum of vectors of its n-grams\n",
    "\n",
    "**3. Sentence Vector (Document representation)**\n",
    "\n",
    "For classification, we need one vector per document, not per word:\n",
    "\n",
    "```python\n",
    "def get_fasttext_embeddings(texts, model):\n",
    "    embeddings[i] = model.get_sentence_vector(text.lower())\n",
    "```\n",
    "\n",
    "**Averages vectors of all words:**\n",
    "$$\\vec{d} = \\frac{1}{n} \\sum_{i=1}^{n} \\vec{w_i}$$\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Text: \"women belong kitchen\"\n",
    "Vector(\"women\") = [0.5, -0.2, 0.8, ...]\n",
    "Vector(\"belong\") = [0.3, 0.1, -0.4, ...]\n",
    "Vector(\"kitchen\") = [0.6, -0.3, 0.2, ...]\n",
    "Vector(document) = [0.47, -0.13, 0.20, ...]  (average)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Process in this cell:**\n",
    "\n",
    "**Step 1: Prepare training file**\n",
    "```python\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", delete=False, encoding='utf-8') as tmp:\n",
    "    for text in X_train:\n",
    "        tmp.write(text.lower() + \"\\n\")\n",
    "```\n",
    "FastText requires a plain text file (one document per line).\n",
    "\n",
    "**Step 2: Train FastText model**\n",
    "```python\n",
    "ft_model = fasttext.train_unsupervised(\n",
    "    train_file_path,\n",
    "    model='skipgram',      # Skip-gram model (predicts context from word)\n",
    "    dim=100,               # 100 dimensions per vector\n",
    "    ws=5,                  # Context window: 5 words on each side\n",
    "    minCount=1,            # Include words appearing ≥1 time\n",
    "    epoch=5,               # 5 complete passes through dataset\n",
    "    thread=4               # 4 CPU threads for parallelization\n",
    ")\n",
    "```\n",
    "\n",
    "**Parameters explained:**\n",
    "- **dim=100**: Each word is represented with 100 real numbers\n",
    "  - More dimensions = more capacity, but more overfitting risk\n",
    "- **ws=5**: Considers 5 words before and 5 after as context\n",
    "  - Large window = captures long-range relationships\n",
    "- **epoch=5**: Model sees each document 5 times during training\n",
    "\n",
    "**Step 3: Generate document embeddings**\n",
    "For each document, we get its 100-dimensional vector by averaging words.\n",
    "\n",
    "**Step 4: Train classifier**\n",
    "Uses same steps as TF-IDF: Logistic Regression + GridSearchCV.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Actual results:**\n",
    "\n",
    "- **FastText shape: (6000, 100)**\n",
    "  - Only 100 features (vs 5,000 from TF-IDF)\n",
    "  - **98% dimensional reduction**\n",
    "  \n",
    "- **Best params: {'C': 0.1}**\n",
    "  - Requires MORE regularization than TF-IDF\n",
    "  - Indicates model tends to overfit\n",
    "  \n",
    "- **F1-Macro (FastText): 0.3357**\n",
    "  - **Only 33.57% precision**\n",
    "  - **-45% worse than TF-IDF (-0.4483 points)**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Why does FastText have such POOR performance here?**\n",
    "\n",
    "**1. Averaging embeddings dilutes discriminative signals**\n",
    "\n",
    "In short texts like memes:\n",
    "```\n",
    "Misogynous meme: \"women belong in the kitchen\"\n",
    "Vector(\"women\") = [0.5, -0.2, ...]\n",
    "Vector(\"belong\") = [0.1, 0.3, ...]\n",
    "Vector(\"in\") = [0.0, 0.1, ...]\n",
    "Vector(\"the\") = [0.0, 0.0, ...]\n",
    "Vector(\"kitchen\") = [0.3, -0.1, ...]\n",
    "Average = [0.18, 0.02, ...]  <- Weak signal\n",
    "```\n",
    "\n",
    "TF-IDF would maintain high importance specifically for \"kitchen\".\n",
    "\n",
    "**2. Small corpus (6,000 documents)**\n",
    "\n",
    "FastText needs **millions of documents** to learn good embeddings:\n",
    "- Pre-trained on Wikipedia: 16B tokens\n",
    "- Our dataset: ~50,000 tokens\n",
    "\n",
    "With small corpus, embeddings are **noisy and unreliable**.\n",
    "\n",
    "**3. Short texts lose context**\n",
    "\n",
    "FastText learns from co-occurrences. In short texts:\n",
    "- Few words per document → little context\n",
    "- Skip-gram cannot learn robust relationships\n",
    "\n",
    "**4. Need for exact lexical signals**\n",
    "\n",
    "In misogyny detection, SPECIFIC words are crucial:\n",
    "- \"bitch\", \"whore\", \"slut\" are strong indicators\n",
    "- FastText generalizes them: \"bitch\" ≈ \"annoying person\" ≈ \"jerk\"\n",
    "- **We lose discriminative specificity**\n",
    "\n",
    "**5. Averaging eliminates order and emphasis**\n",
    "\n",
    "```\n",
    "\"Kitchen belongs to women\" vs \"Women belong in kitchen\"\n",
    "```\n",
    "Both have the same averaged vectors, although emphasis is different.\n",
    "\n",
    "---\n",
    "\n",
    "#### **When does FastText work well?**\n",
    "\n",
    "Works well for:\n",
    "- **Long documents**: Articles, reviews, essays\n",
    "- **Large corpus**: Millions of documents\n",
    "- **Semantic generalization important**: \"cellphone\", \"mobile\", \"smartphone\" should be treated equally\n",
    "- **Similarity tasks**: Finding related documents\n",
    "- **Rare words/typos**: Texts with much orthographic noise\n",
    "\n",
    "Does NOT work well for:\n",
    "- Short texts (tweets, memes)\n",
    "- Detection of specific offensive words\n",
    "- Small corpus\n",
    "- Need for exact lexical signals\n",
    "\n",
    "---\n",
    "\n",
    "#### **Conclusion:**\n",
    "\n",
    "FastText represents a fundamentally different approach from TF-IDF:\n",
    "- **TF-IDF**: Sparse, lexical, explicit representation\n",
    "- **FastText**: Dense, semantic, generalized representation\n",
    "\n",
    "For this specific problem (classifying short memes with small corpus), **TF-IDF is superior** because:\n",
    "1. Maintains exact discriminative signals\n",
    "2. Does not dilute information by averaging\n",
    "3. Does not require large amounts of data\n",
    "4. Captures presence/absence of offensive keywords\n",
    "\n",
    "FastText is a powerful tool, but **not suitable for this use case**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f80f5",
   "metadata": {},
   "source": [
    "## Comparison of TF-IDF (Sparse) and FastText (Dense) Representations\n",
    "\n",
    "In this experiment, we trained and evaluated two different text representation approaches on a dataset of 7,500 meme texts. The task consists of binary classification of the *misogynous* label. The data were split into training and test sets using an 80/20 stratified split, resulting in 6,000 training samples and 1,500 test samples.\n",
    "\n",
    "Both approaches use the same downstream classifier (Logistic Regression), the same hyperparameter tuning strategy (GridSearchCV over the regularization parameter C), and the same evaluation metric (F1-macro). This ensures that any performance differences are due to the text representation rather than the classification algorithm.\n",
    "\n",
    "### TF-IDF (Sparse Representation)\n",
    "\n",
    "TF-IDF produces a high-dimensional sparse matrix where each feature corresponds to a specific word in the vocabulary (up to 5,000 features). The value of each feature reflects the importance of the word in a document relative to the corpus.\n",
    "\n",
    "This representation captures exact lexical information. If certain words or phrases are strongly associated with misogynous content, TF-IDF preserves these signals directly. Since meme texts are typically short and often rely on explicit wording, keyword presence becomes highly informative. Logistic Regression performs particularly well in high-dimensional sparse spaces, making TF-IDF a strong baseline for this type of task.\n",
    "\n",
    "However, TF-IDF does not model semantic similarity. Words with similar meanings are treated as completely independent features.\n",
    "\n",
    "### FastText (Dense Representation)\n",
    "\n",
    "FastText produces low-dimensional dense vectors (100 dimensions in this case). It learns word embeddings using contextual information and incorporates subword information, which helps handle rare or misspelled words. Each document is represented as a single sentence vector.\n",
    "\n",
    "Unlike TF-IDF, FastText captures semantic relationships between words. Words that appear in similar contexts are mapped to nearby points in the embedding space. This allows some degree of generalization beyond exact word matching.\n",
    "\n",
    "However, in this setup, document embeddings are obtained by averaging word vectors. For short meme texts, averaging can dilute strong discriminative signals. If a single offensive or highly indicative word determines the label, averaging may reduce its impact within the final representation.\n",
    "\n",
    "### Sparse vs Dense Approaches in Meme Text Classification\n",
    "\n",
    "Meme texts tend to be short, noisy, and strongly dependent on specific lexical cues. In such cases:\n",
    "\n",
    "* Sparse representations preserve exact word presence and frequency.\n",
    "* Dense representations compress information into a limited number of dimensions.\n",
    "* Averaging word embeddings may smooth out extreme signals.\n",
    "\n",
    "Because the dataset consists of short texts and the target label (misogynous) is often triggered by explicit terms, TF-IDF is structurally well-suited to the problem. FastText, while semantically richer, may require larger corpora or longer documents to fully leverage its representational power.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The comparison highlights the fundamental difference between sparse lexical features and dense semantic embeddings. TF-IDF relies on direct word statistics and performs well when specific keywords drive the classification decision. FastText captures contextual similarity and generalization but may underperform when the task depends heavily on explicit lexical cues within short texts.\n",
    "\n",
    "In this meme classification setting, the sparse TF-IDF approach is often better aligned with the characteristics of the data, while the dense FastText embeddings provide a more compact but potentially less discriminative representation for this specific task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49682f6e",
   "metadata": {},
   "source": [
    "## Unigrams vs Bigrams vs Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8251290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N-gram Exploration (TF-IDF) ===\n",
      "\n",
      "--- Unigrams ---\n",
      "Best C: {'C': 1}\n",
      "F1-Macro: 0.7840\n",
      "\n",
      "--- Bigrams ---\n",
      "Best C: {'C': 1}\n",
      "F1-Macro: 0.7873\n",
      "\n",
      "--- Trigrams ---\n",
      "Best C: {'C': 1}\n",
      "F1-Macro: 0.7873\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== N-gram Exploration (TF-IDF) ===\")\n",
    "\n",
    "ngram_configs = {\n",
    "    \"Unigrams\": (1, 1),\n",
    "    \"Bigrams\": (1, 2),\n",
    "    \"Trigrams\": (1, 3)\n",
    "}\n",
    "\n",
    "results_ngram = {}\n",
    "\n",
    "for name, ngram_range in ngram_configs.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        ngram_range=ngram_range,\n",
    "        lowercase=True\n",
    "    )\n",
    "\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "        {'C': [0.1, 1, 10]},\n",
    "        cv=5,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train_vec, y_train)\n",
    "    y_pred = grid.predict(X_test_vec)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    results_ngram[name] = f1\n",
    "\n",
    "    print(f\"Best C: {grid.best_params_}\")\n",
    "    print(f\"F1-Macro: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0ca104",
   "metadata": {},
   "source": [
    "### Explanation: N-grams Exploration (Unigrams, Bigrams, Trigrams)\n",
    "\n",
    "**What are N-grams?**\n",
    "\n",
    "**N-grams** are contiguous sequences of n words. Instead of considering only individual words, we can capture complete phrases.\n",
    "\n",
    "#### **Types of N-grams:**\n",
    "\n",
    "**Unigrams (1-gram)**: Individual words\n",
    "```\n",
    "Text: \"women belong in kitchen\"\n",
    "Unigrams: [\"women\", \"belong\", \"in\", \"kitchen\"]\n",
    "```\n",
    "\n",
    "**Bigrams (2-gram)**: Consecutive word pairs\n",
    "```\n",
    "Text: \"women belong in kitchen\"\n",
    "Unigrams: [\"women\", \"belong\", \"in\", \"kitchen\"]\n",
    "Bigrams: [\"women belong\", \"belong in\", \"in kitchen\"]\n",
    "Total features: 4 unigrams + 3 bigrams = 7 features\n",
    "```\n",
    "\n",
    "**Trigrams (3-gram)**: Consecutive word triplets\n",
    "```\n",
    "Text: \"women belong in kitchen\"\n",
    "Unigrams: [\"women\", \"belong\", \"in\", \"kitchen\"]\n",
    "Bigrams: [\"women belong\", \"belong in\", \"in kitchen\"]\n",
    "Trigrams: [\"women belong in\", \"belong in kitchen\"]\n",
    "Total features: 4 + 3 + 2 = 9 features\n",
    "```\n",
    "\n",
    "#### **Why use N-grams?**\n",
    "\n",
    "**Advantages:**\n",
    "- Capture **local context**: \"not good\" has different meaning than \"good\"\n",
    "- Detect **specific phrases**: \"get back to kitchen\" is more informative than separate words\n",
    "- Capture **modifiers**: \"very offensive\" vs \"offensive\"\n",
    "\n",
    "**Disadvantages:**\n",
    "- **Higher dimensionality**: More features = more overfitting risk\n",
    "- **Data sparsity**: Many combinations appear only 1-2 times\n",
    "- **Less generalization**: \"belong in kitchen\" and \"belong to kitchen\" are different bigrams\n",
    "\n",
    "#### **Configurations tested:**\n",
    "\n",
    "```python\n",
    "ngram_configs = {\n",
    "    \"Unigrams\": (1, 1),    # Only individual words\n",
    "    \"Bigrams\": (1, 2),     # Words + pairs \n",
    "    \"Trigrams\": (1, 3)     # Words + pairs + triplets\n",
    "}\n",
    "```\n",
    "\n",
    "Note: `(1, 2)` means \"include from 1-grams to 2-grams\", not only 2-grams.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Actual results:**\n",
    "\n",
    "**Unigrams (1,1):**\n",
    "- **Best C**: 1\n",
    "- **F1-Macro: 0.7840** (baseline)\n",
    "\n",
    "**Bigrams (1,2):**\n",
    "- **Best C**: 1\n",
    "- **F1-Macro: 0.7873** \n",
    "- **+0.33% improvement** (+0.0033 points)\n",
    "\n",
    "**Trigrams (1,3):**\n",
    "- **Best C**: 1\n",
    "- **F1-Macro: 0.7873**\n",
    "- **No additional improvement** over bigrams\n",
    "\n",
    "---\n",
    "\n",
    "#### **Results analysis:**\n",
    "\n",
    "**Why do bigrams improve?**\n",
    "\n",
    "They capture some discriminative phrases:\n",
    "- \"belong to\" / \"get back\" / \"shut up\"\n",
    "- \"sandwich maker\" / \"dishwasher joke\"\n",
    "- Context that modifies meaning\n",
    "\n",
    "**Why don't trigrams improve further?**\n",
    "\n",
    "1. **Short texts**: Memes have few words, trigrams are very specific\n",
    "2. **Sparsity**: Most trigrams appear only once\n",
    "3. **max_features=5000**: The limit eliminates rare trigrams, keeping only most common\n",
    "4. **Overfitting**: Trigrams memorize exact phrases without generalizing\n",
    "\n",
    "**Example of useful bigrams vs useless trigrams:**\n",
    "\n",
    "```\n",
    "Useful bigram: \"in kitchen\" (appears frequently in misogynous contexts)\n",
    "Sparse trigram: \"women in kitchen\" vs \"woman in kitchen\" vs \"girls in kitchen\"\n",
    "→ 3 separate features with few examples each\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Conclusion:**\n",
    "\n",
    "- **Bigrams offer slight improvement** (78.73% vs 78.40%)\n",
    "- Bigrams capture short discriminative phrases\n",
    "- **Trigrams add no additional value** in this dataset\n",
    "- For short texts like memes, **bigrams (1,2) is optimal**\n",
    "\n",
    "**Recommendation**: Use `ngram_range=(1, 2)` in production to capture the best balance between context and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e7d2d",
   "metadata": {},
   "source": [
    "## Different preprocessing configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b6f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Wassim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Wassim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Preprocessing Ablation (TF-IDF) ===\n",
      "\n",
      "--- Raw ---\n",
      "F1-Macro: 0.7840\n",
      "\n",
      "--- Lowercase ---\n",
      "F1-Macro: 0.7840\n",
      "\n",
      "--- Stopword Removal ---\n",
      "F1-Macro: 0.7846\n",
      "\n",
      "--- Lemmatization ---\n",
      "F1-Macro: 0.7813\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text, lowercase=True, remove_stop=False, lemmatize=False):\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    words = text.split()\n",
    "\n",
    "    if remove_stop:\n",
    "        words = [w for w in words if w not in stop_words]\n",
    "\n",
    "    if lemmatize:\n",
    "        words = [lemmatizer.lemmatize(w) for w in words]\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "\n",
    "configs = {\n",
    "    \"Raw\": {\"lowercase\": False, \"remove_stop\": False, \"lemmatize\": False},\n",
    "    \"Lowercase\": {\"lowercase\": True, \"remove_stop\": False, \"lemmatize\": False},\n",
    "    \"Stopword Removal\": {\"lowercase\": True, \"remove_stop\": True, \"lemmatize\": False},\n",
    "    \"Lemmatization\": {\"lowercase\": True, \"remove_stop\": True, \"lemmatize\": True}\n",
    "}\n",
    "\n",
    "print(\"\\n=== Preprocessing Ablation (TF-IDF) ===\")\n",
    "\n",
    "for name, config in configs.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "\n",
    "    X_train_prep = X_train.apply(lambda x: preprocess_text(x, **config))\n",
    "    X_test_prep = X_test.apply(lambda x: preprocess_text(x, **config))\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_train_vec = vectorizer.fit_transform(X_train_prep)\n",
    "    X_test_vec = vectorizer.transform(X_test_prep)\n",
    "\n",
    "    grid.fit(X_train_vec, y_train)\n",
    "    y_pred = grid.predict(X_test_vec)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"F1-Macro: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47536b2",
   "metadata": {},
   "source": [
    "### Explanation: Text Preprocessing Impact\n",
    "\n",
    "**What does this cell do?**\n",
    "\n",
    "Tests **different preprocessing levels** to determine if cleaning and normalizing text improves classification.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Preprocessing function:**\n",
    "\n",
    "```python\n",
    "def preprocess_text(text, lowercase=True, remove_stop=False, lemmatize=False):\n",
    "```\n",
    "\n",
    "**Preprocessing steps:**\n",
    "\n",
    "1. **Lowercase** (Convert to lowercase):\n",
    "   - `\"WOMEN\"` → `\"women\"`\n",
    "   - `\"Woman\"` → `\"woman\"`\n",
    "   - Normalizes capitalization variations\n",
    "\n",
    "2. **Special character removal**:\n",
    "   ```python\n",
    "   text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "   ```\n",
    "   - `\"women!!!\"` → `\"women\"`\n",
    "   - `\"she's\"` → `\"shes\"`\n",
    "   - Removes punctuation numbers, emojis\n",
    "\n",
    "3. **Stopword Removal** (Remove empty words):\n",
    "   - Stopwords: `[\"the\", \"is\", \"a\", \"an\", \"in\", \"to\", \"and\", ...]`\n",
    "   - `\"the woman is in the kitchen\"` → `\"woman kitchen\"`\n",
    "   - Reduces dimensionality removing non-informative words\n",
    "\n",
    "4. **Lemmatization**:\n",
    "   - Reduces words to base/root form\n",
    "   - `\"running\"` → `\"run\"`\n",
    "   - `\"women\"` → `\"woman\"`\n",
    "   - `\"better\"` → `\"good\"`\n",
    "   - `\"was\"` → `\"be\"`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Configurations tested:**\n",
    "\n",
    "```python\n",
    "configs = {\n",
    "    \"Raw\": No preprocessing\n",
    "    \"Lowercase\": Only lowercase\n",
    "    \"Stopword Removal\": Lowercase + no stopwords\n",
    "    \"Lemmatization\": Lowercase + no stopwords + lemmatization\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Actual results:**\n",
    "\n",
    "| Configuration | F1-Macro | Change vs Raw |\n",
    "|---------------|----------|---------------|\n",
    "| **Raw** | 0.7840 | baseline |\n",
    "| **Lowercase** | 0.7840 | **0.00%** (no change) |\n",
    "| **Stopword Removal** | 0.7846 | **+0.06%** (+0.0006) |\n",
    "| **Lemmatization** | 0.7813 | **-0.27%** (-0.0027) |\n",
    "\n",
    "---\n",
    "\n",
    "#### **Detailed analysis:**\n",
    "\n",
    "**1. Why does Lowercase NOT change anything?**\n",
    "\n",
    "`TfidfVectorizer` already includes `lowercase=True` by default:\n",
    "```python\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, lowercase=True)\n",
    "```\n",
    "Therefore, applying lowercase manually is redundant.\n",
    "\n",
    "**2. Why does Stopword Removal improve slightly?**\n",
    "\n",
    "**Stopwords removed:** \"the\", \"is\", \"a\", \"an\", \"in\", \"to\", \"of\", \"and\", \"that\", \"this\", etc.\n",
    "\n",
    "**Advantages:**\n",
    "- Reduces noise: stopwords have low TF-IDF but occupy space in `max_features=5000`\n",
    "- By removing them, **more discriminative words** enter the top 5000\n",
    "- Example: Instead of including \"the\" (non-informative), includes \"sandwich\" (potentially discriminative)\n",
    "\n",
    "**Disadvantage:**\n",
    "- Some stopwords may be useful in context:\n",
    "  - \"in\" in \"belong **in** kitchen\" has meaning\n",
    "  - \"to\" in \"get back **to** kitchen\" marks direction\n",
    "\n",
    "**Minimal improvement (+0.06%)** indicates stopwords really don't contribute much.\n",
    "\n",
    "**3. Why does Lemmatization WORSEN performance?**\n",
    "\n",
    "**Lemmatization groups variations:**\n",
    "- `\"woman\"`, `\"women\"` → all `\"woman\"`\n",
    "- `\"he\"`, `\"him\"`, `\"his\"` → all `\"he\"`\n",
    "- `\"better\"`, `\"best\"`, `\"good\"` → all `\"good\"`\n",
    "\n",
    "**Problem: Loss of discriminative information**\n",
    "\n",
    "**Example 1 - Loss of gender/number:**\n",
    "```\n",
    "Original: \"women are stupid\" (plural, feminine)\n",
    "Lemmatized: \"woman be stupid\"\n",
    "```\n",
    "**Plural vs singular** could be signal:\n",
    "- \"Women are X\" (generalization about all women) → more misogynous\n",
    "- \"A woman is X\" (reference to specific woman) → less generalized\n",
    "\n",
    "**Example 2 - Loss of verb tense:**\n",
    "```\n",
    "Original: \"she was asking for it\"\n",
    "Lemmatized: \"she be ask for it\"\n",
    "```\n",
    "Past tense may have specific connotations.\n",
    "\n",
    "**Example 3 - Loss of variants:**\n",
    "```\n",
    "Original: Vocabulary = {\"woman\": 50 docs, \"women\": 80 docs}\n",
    "→ IDF(\"woman\") ≠ IDF(\"women\")\n",
    "\n",
    "Lemmatized: Vocabulary = {\"woman\": 130 docs}\n",
    "→ Lower IDF (word appears in more documents)\n",
    "```\n",
    "\n",
    "**Conclusion about lemmatization:**\n",
    "\n",
    "Lemmatization is useful when:\n",
    "- Small corpus with many variants\n",
    "- Semantic search\n",
    "- Data with many spelling errors\n",
    "\n",
    "Lemmatization is NOT useful when:\n",
    "- Morphological variations are discriminative (gender, number, tense)\n",
    "- Dataset is already large enough\n",
    "- Need exact signals\n",
    "\n",
    "In misogyny detection, **variations matter**:\n",
    "- \"woman\" vs \"women\" (singular vs generalization)\n",
    "- \"slut\" vs \"sluts\" (individual target vs group)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Final recommendation:**\n",
    "\n",
    "**Best configuration**: **Stopword Removal**\n",
    "- F1-Macro: 0.7846\n",
    "- Removes non-informative words without losing discriminative information\n",
    "- Optimal balance between simplicity and performance\n",
    "\n",
    "**DO NOT use**:\n",
    "- Raw (includes stopword noise)\n",
    "- Lemmatization (loses useful information)\n",
    "\n",
    "**For production**: \n",
    "```python\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    lowercase=True,\n",
    "    stop_words='english'  # Best configuration\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8cc4b",
   "metadata": {},
   "source": [
    "## Greater hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042c5171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "param_grid_extended = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_extended = GridSearchCV(\n",
    "    LogisticRegression(max_iter=2000, random_state=RANDOM_STATE),\n",
    "    param_grid_extended,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_extended.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Best params:\", grid_extended.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4cd6d",
   "metadata": {},
   "source": [
    "### Explanation: Extended Hyperparameter Optimization\n",
    "\n",
    "**What does this cell do?**\n",
    "\n",
    "Extends the search for **regularization parameter C** in Logistic Regression to confirm the optimal value was already found.\n",
    "\n",
    "---\n",
    "\n",
    "#### **What is parameter C?**\n",
    "\n",
    "**C** is the **inverse of regularization strength** in Logistic Regression:\n",
    "\n",
    "$$\\text{Loss} = \\text{Classification error} + \\frac{1}{C} \\times \\text{Weight penalty}$$\n",
    "\n",
    "**C values:**\n",
    "\n",
    "| C value | Regularization | Effect | When to use |\n",
    "|---------|----------------|--------|-------------|\n",
    "| **C = 0.01** | Very high | Very simple model, small weights | Little data, much noise |\n",
    "| **C = 0.1** | High | Simple model, avoids overfitting | Small dataset |\n",
    "| **C = 1** | Moderate | Balance between complexity and generalization | **Optimal default** |\n",
    "| **C = 10** | Low | More complex model, allows large weights | Large dataset |\n",
    "| **C = 100** | Very low | Very complex model, overfitting risk | Lots of data, clear signal |\n",
    "\n",
    "**Intuition:**\n",
    "- **Small C** → Model prefers small weights (simple) even if it classifies worse\n",
    "- **Large C** → Model prioritizes classifying well even using large weights (complex)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Extended search:**\n",
    "\n",
    "```python\n",
    "param_grid_extended = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100]  # 5 values in logarithmic scale\n",
    "}\n",
    "```\n",
    "\n",
    "Previously we only tested `[0.1, 1, 10]`, now we extend to more extreme values.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Actual results:**\n",
    "\n",
    "**Best params: {'C': 1}**\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "The optimal value remains **C = 1**, confirming that:\n",
    "\n",
    "1. **We don't need more regularization** (C < 1 would worsen)\n",
    "   - Model is NOT significantly overfitting\n",
    "   \n",
    "2. **We don't need less regularization** (C > 1 would worsen)\n",
    "   - Allowing larger weights does not help\n",
    "   - More complexity → more overfitting without gain\n",
    "\n",
    "3. **C = 1 is the perfect balance** for this problem\n",
    "   - 6,000 training examples\n",
    "   - 5,000 features\n",
    "   - sklearn default turns out to be optimal\n",
    "\n",
    "---\n",
    "\n",
    "#### **Why is C = 1 optimal?**\n",
    "\n",
    "**If C = 0.01 were better:**\n",
    "- Would indicate much noise in data\n",
    "- Model would need to be very conservative\n",
    "- Not happening here\n",
    "\n",
    "**If C = 100 were better:**\n",
    "- Would indicate we need more complexity\n",
    "- Data has clear patterns requiring large weights\n",
    "- Also not happening\n",
    "\n",
    "**C = 1 optimal indicates:**\n",
    "- Well-balanced dataset in signal/noise\n",
    "- Appropriate number of features (5,000)\n",
    "- Adequate data/features ratio (6,000/5,000 = 1.2)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Important lesson:**\n",
    "\n",
    "**GridSearchCV with cross-validation** is crucial to avoid overfitting in hyperparameter selection:\n",
    "\n",
    "```python\n",
    "grid_extended = GridSearchCV(cv=5, ...)\n",
    "```\n",
    "\n",
    "1. Divides train into 5 parts\n",
    "2. For each C value:\n",
    "   - Trains on 4 parts\n",
    "   - Validates on 1 part\n",
    "   - Repeats 5 times (1 for each fold)\n",
    "3. Averages F1-score of 5 validations\n",
    "4. Chooses C with best average\n",
    "\n",
    "This ensures **chosen C generalizes well** and doesn't just memorize a particular split.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Conclusion:**\n",
    "\n",
    "Extended search **confirms C = 1 is optimal**. No need to explore more extreme values. The model has adequate regularization for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cb1d8",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1afc493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_tfidf)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='magma')\n",
    "plt.title(\"Confusion Matrix (TF-IDF)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da41987b",
   "metadata": {},
   "source": [
    "### Explanation: Confusion Matrix - Error Analysis\n",
    "\n",
    "**What is a Confusion Matrix?**\n",
    "\n",
    "The **confusion matrix** shows exactly **where the model makes mistakes**, distinguishing between different types of errors.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Matrix interpretation:**\n",
    "\n",
    "The obtained matrix has this structure:\n",
    "\n",
    "```\n",
    "                 Predicted: 0    Predicted: 1\n",
    "Real: 0              599            143        = 742 (total class 0)\n",
    "Real: 1              181            577        = 758 (total class 1)\n",
    "                     ___            ___\n",
    "                     780            720        = 1,500 total\n",
    "```\n",
    "\n",
    "**Four categories:**\n",
    "\n",
    "1. **True Negatives (TN) = 599** (upper left cell)\n",
    "   - Real: 0 (non-misogynous) → Predicted: 0 (non-misogynous)\n",
    "   - Correct: Correctly identified 599 NON-misogynous memes\n",
    "\n",
    "2. **False Positives (FP) = 143** (upper right cell)\n",
    "   - Real: 0 (non-misogynous) → Predicted: 1 (misogynous)\n",
    "   - Error Type I: Classified 143 innocent memes as misogynous\n",
    "   - **Example**: Sarcasm, empathetic context misinterpreted\n",
    "\n",
    "3. **False Negatives (FN) = 181** (lower left cell)\n",
    "   - Real: 1 (misogynous) → Predicted: 0 (non-misogynous)\n",
    "   - Error Type II: Did NOT detect 181 misogynous memes\n",
    "   - **Example**: Subtle, implicit, ironic misogyny\n",
    "\n",
    "4. **True Positives (TP) = 577** (lower right cell)\n",
    "   - Real: 1 (misogynous) → Predicted: 1 (misogynous)\n",
    "   - Correct: Correctly detected 577 misogynous memes\n",
    "\n",
    "---\n",
    "\n",
    "#### **Derived metrics:**\n",
    "\n",
    "**Precision** - Of what it predicted as positive, how much did it get right?\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP} = \\frac{577}{577 + 143} = \\frac{577}{720} = 80.1\\%$$\n",
    "\n",
    "**Interpretation**: When the model says \"this is misogynous\", it's correct **80.1%** of the time.\n",
    "\n",
    "**Recall (Sensitivity)** - Of all real positives, how many did it detect?\n",
    "$$\\text{Recall} = \\frac{TP}{TP + FN} = \\frac{577}{577 + 181} = \\frac{577}{758} = 76.1\\%$$\n",
    "\n",
    "**Interpretation**: The model detects **76.1%** of all real misogynous memes.\n",
    "\n",
    "**Specificity** - Of all real negatives, how many did it identify?\n",
    "$$\\text{Specificity} = \\frac{TN}{TN + FP} = \\frac{599}{599 + 143} = \\frac{599}{742} = 80.7\\%$$\n",
    "\n",
    "**Interpretation**: The model correctly identifies **80.7%** of NON-misogynous memes.\n",
    "\n",
    "**F1-Score** - Harmonic mean of Precision and Recall\n",
    "$$F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} = 2 \\times \\frac{0.801 \\times 0.761}{0.801 + 0.761} = 78.0\\%$$\n",
    "\n",
    "**Accuracy (Overall accuracy)**\n",
    "$$\\text{Accuracy} = \\frac{TP + TN}{\\text{Total}} = \\frac{577 + 599}{1500} = \\frac{1176}{1500} = 78.4\\%$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Error analysis:**\n",
    "\n",
    "**False Positives (143 cases) - \"False alarm\"**\n",
    "\n",
    "Model classifies as misogynous when it's NOT:\n",
    "\n",
    "**Possible causes:**\n",
    "- **Humor or sarcasm**: \"Women are great... at nagging\" (ambiguous humorous intent)\n",
    "- **Positive context with keywords**: Contains \"women\", \"kitchen\" but in empathetic context\n",
    "- **Irony**: Criticism of misogyny that model interprets literally\n",
    "- **Descriptive mentions**: Describing misogyny without being it\n",
    "\n",
    "**Impact**: \n",
    "- In content moderation: **Excessive censorship**, blocks legitimate content\n",
    "- In research: **False findings**, exaggerates prevalence\n",
    "\n",
    "**False Negatives (181 cases) - \"Not detected\"**\n",
    "\n",
    "Model does NOT detect real misogynous content:\n",
    "\n",
    "**Possible causes:**\n",
    "- **Subtle or implicit misogyny**: Without obvious keywords\n",
    "- **Coded language**: Metaphors, euphemisms\n",
    "- **Visual context**: Image is misogynous but text is not (multimodal)\n",
    "- **New expressions**: Emerging language not in vocabulary\n",
    "- **Complex irony**: Multiple interpretation levels\n",
    "\n",
    "**Impact**:\n",
    "- In moderation: **Harmful content goes undetected**\n",
    "- In research: **Problem underestimation**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Error balance:**\n",
    "\n",
    "**FP (143) vs FN (181)**:\n",
    "- **More False Negatives** than False Positives\n",
    "- Model is slightly **conservative** (prefers not to classify as misogynous if in doubt)\n",
    "\n",
    "**Which balance is better?**\n",
    "\n",
    "Depends on application:\n",
    "\n",
    "**If we prioritize Recall (minimize FN):**\n",
    "- Automatic social media moderation\n",
    "- Want to detect ALL problematic content\n",
    "- Accept some false positives (human review afterwards)\n",
    "\n",
    "**If we prioritize Precision (minimize FP):**\n",
    "- Automatic reporting systems\n",
    "- Don't want to accuse wrongly\n",
    "- Accept that something may escape\n",
    "\n",
    "**For this case**: F1-macro balances both, appropriate for research.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Matrix visualization:**\n",
    "\n",
    "The graph shows (with magma colormap):\n",
    "- **Light yellow**: High values (TP=577, TN=599) - Correct predictions\n",
    "- **Dark purple**: Lower values (FP=143, FN=181) - Errors\n",
    "\n",
    "The matrix is **reasonably balanced** on the diagonal, indicating good overall performance.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Conclusion:**\n",
    "\n",
    "The model makes **324 errors** out of 1,500 predictions (21.6% error rate):\n",
    "- 143 false positives (9.5%)\n",
    "- 181 false negatives (12.1%)\n",
    "\n",
    "The **78.4% accuracy** performance is solid but there's room for improvement, especially in **reducing false negatives** (detecting subtle misogyny)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb9b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top misogynous indicators:\n",
      "employees 5.119718781460164\n",
      "wouldn 4.587137236249068\n",
      "fits 4.387153034454303\n",
      "attracted 4.008844309208959\n",
      "course 3.7688390243371743\n",
      "dank 3.454152852414472\n",
      "preach 3.3245803646239898\n",
      "privileged 2.749794107261883\n",
      "before 2.6808239161577685\n",
      "wow 2.6788932388135023\n",
      "remains 2.50965920817369\n",
      "misses 2.487049385363048\n",
      "maybe 2.414329382426296\n",
      "empire 2.397893064558269\n",
      "wonderful 2.3964648437046465\n",
      "thoughts 2.0688492980442823\n",
      "battle 2.016470041941357\n",
      "ou 2.0102658334083188\n",
      "see 1.934604956701796\n",
      "camera 1.927922619410724\n",
      "\n",
      "Top non-misogynous indicators:\n",
      "hate -4.111552004292633\n",
      "buys -2.9291715358711587\n",
      "ork -2.879852869819371\n",
      "clientis -2.8082849325480925\n",
      "cash -2.710125532423727\n",
      "following -2.5045076304961986\n",
      "box -2.425424727062876\n",
      "worth -2.1346805249004595\n",
      "brought -2.106874368096272\n",
      "five -1.9762665370977446\n",
      "which -1.7422580300626116\n",
      "poverty -1.6861385186305407\n",
      "matters -1.6415971542893295\n",
      "pt -1.639837410954668\n",
      "closes -1.6376290247364758\n",
      "max -1.6247356457265734\n",
      "whether -1.5792859223936555\n",
      "olej -1.502147609450484\n",
      "cold -1.421094143232723\n",
      "fear -1.4200558934404164\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "coefs = grid.best_estimator_.coef_[0]\n",
    "\n",
    "top_positive = np.argsort(coefs)[-20:]\n",
    "top_negative = np.argsort(coefs)[:20]\n",
    "\n",
    "print(\"Top misogynous indicators:\")\n",
    "for idx in reversed(top_positive):\n",
    "    print(feature_names[idx], coefs[idx])\n",
    "\n",
    "print(\"\\nTop non-misogynous indicators:\")\n",
    "for idx in top_negative:\n",
    "    print(feature_names[idx], coefs[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6c2351",
   "metadata": {},
   "source": [
    "### Explanation: Feature Importance Analysis - Most Discriminative Words\n",
    "\n",
    "**What does this cell do?**\n",
    "\n",
    "Extracts **model coefficients** from Logistic Regression to identify which words are most important for classification.\n",
    "\n",
    "---\n",
    "\n",
    "#### **How do coefficients work in Logistic Regression?**\n",
    "\n",
    "Logistic Regression calculates the probability of a document being misogynous using:\n",
    "\n",
    "$$P(\\text{misogynous} | \\text{document}) = \\sigma(w_1 \\cdot x_1 + w_2 \\cdot x_2 + ... + w_n \\cdot x_n + b)$$\n",
    "\n",
    "Where:\n",
    "- $x_i$ = TF-IDF of term $i$ in document\n",
    "- $w_i$ = **coefficient** of term $i$ (what we extract here)\n",
    "- $\\sigma$ = sigmoid function (converts to probability 0-1)\n",
    "\n",
    "**Coefficient interpretation:**\n",
    "- **Large POSITIVE coefficient** → Word indicates misogyny\n",
    "- **Large NEGATIVE coefficient** → Word indicates NON-misogyny\n",
    "- **Coefficient near 0** → Non-discriminative word\n",
    "\n",
    "---\n",
    "\n",
    "#### **Code explained:**\n",
    "\n",
    "```python\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()  # All words\n",
    "coefs = grid.best_estimator_.coef_[0]  # Coefficients from best model\n",
    "\n",
    "top_positive = np.argsort(coefs)[-20:]  # Indices of 20 highest coefficients\n",
    "top_negative = np.argsort(coefs)[:20]   # Indices of 20 lowest coefficients\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Actual results:**\n",
    "\n",
    "**TOP 20 MISOGYNOUS INDICATORS** (positive coefficients):\n",
    "\n",
    "| Word | Coefficient | Interpretation |\n",
    "|------|-------------|----------------|\n",
    "| employees | +5.12 | Possibly workplace contexts with discrimination |\n",
    "| wouldn | +4.59 | \"wouldn't\" in condescending contexts |\n",
    "| fits | +4.39 | Possible references to physical appearance |\n",
    "| attracted | +4.01 | Objectification, reduction to sexual attractiveness |\n",
    "| course | +3.77 | Sarcasm (\"of course women...\") |\n",
    "| dank | +3.45 | Meme culture, sometimes misogynous |\n",
    "| preach | +3.32 | Context of mandates (\"preach\" ironically) |\n",
    "| privileged | +2.75 | Possible anti-feminist sarcasm |\n",
    "| before | +2.68 | Temporal contexts (\"before feminism\") |\n",
    "| wow | +2.68 | Sarcastic expression |\n",
    "| misses | +2.49 | References to \"Mrs.\" or errors |\n",
    "| maybe | +2.41 | Condescension (\"maybe women should...\") |\n",
    "| empire | +2.40 | Specific historical or cultural context |\n",
    "| wonderful | +2.40 | Sarcasm (\"wonderful women drivers\") |\n",
    "| thoughts | +2.07 | Questioning intellectual capacity |\n",
    "\n",
    "**Important observation:** Many apparently neutral words are indicators because they appear in **sarcastic or ironic contexts**. They are not inherently misogynous, but the model learned they co-occur with problematic content.\n",
    "\n",
    "---\n",
    "\n",
    "**TOP 20 NON-MISOGYNOUS INDICATORS** (negative coefficients):\n",
    "\n",
    "| Word | Coefficient | Interpretation |\n",
    "|------|-------------|----------------|\n",
    "| hate | -4.11 | **Counterintuitively negative** - possible anti-hate speech |\n",
    "| buys | -2.93 | Neutral consumption contexts |\n",
    "| ork | -2.88 | Possible typo or specific term |\n",
    "| clientis | -2.81 | Professional/commercial context |\n",
    "| cash | -2.71 | Neutral economic contexts |\n",
    "| following | -2.50 | Descriptive narrative |\n",
    "| box | -2.43 | Neutral object |\n",
    "| worth | -2.13 | Evaluations unrelated to gender |\n",
    "| brought | -2.11 | Neutral action verbs |\n",
    "| five | -1.98 | Generally neutral numbers |\n",
    "| which | -1.74 | Neutral relative pronoun |\n",
    "| poverty | -1.69 | Serious socio-economic topics |\n",
    "| matters | -1.64 | Social justice discourses (irony: may be feminist) |\n",
    "| whether | -1.58 | Neutral grammatical construction |\n",
    "| cold | -1.42 | Physical/environmental description |\n",
    "| fear | -1.42 | Emotion in non-misogynous context |\n",
    "\n",
    "---\n",
    "\n",
    "#### **Deep analysis:**\n",
    "\n",
    "**Why is \"hate\" a NON-misogynous indicator?**\n",
    "\n",
    "Counterintuitive, but logical:\n",
    "1. **Openly misogynous** memes usually use euphemisms, not direct \"hate\"\n",
    "2. Use of \"hate\" may indicate **denunciation of misogyny**:\n",
    "   - \"I hate when people say women belong in kitchen\"\n",
    "   - \"Don't hate women\"\n",
    "3. Anti-hate content (feminist) uses the word frequently\n",
    "\n",
    "**Interesting patterns:**\n",
    "\n",
    "**Sarcasm detected by model:**\n",
    "- \"wonderful\", \"wow\", \"course\" → Apparently positive but used ironically\n",
    "- Model learned these words co-occur with problematic content\n",
    "\n",
    "**Contextual neutral words:**\n",
    "- \"employees\", \"before\", \"maybe\" → Neutral per se, but in certain contexts signal discrimination\n",
    "\n",
    "**Model limitation:**\n",
    "- Doesn't understand **negation**: \"NOT attracted\" vs \"attracted\" have same TF-IDF for \"attracted\"\n",
    "- Doesn't capture **complex irony**: Depends on individual words, not rhetorical structure\n",
    "\n",
    "---\n",
    "\n",
    "#### **Recommended manual validation:**\n",
    "\n",
    "For each high-importance word, we should:\n",
    "1. Search examples in dataset\n",
    "2. Verify if pattern is genuine or spurious\n",
    "3. Understand usage context\n",
    "\n",
    "**Example**: Search all documents with \"employees\" and see why it has such high coefficient.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Practical application:**\n",
    "\n",
    "**Keywords for basic filtering:**\n",
    "```python\n",
    "misogyny_indicators = [\n",
    "    \"attracted\", \"fits\", \"course\", \"privileged\", \n",
    "    \"wonderful\" (sarcastically), \"thoughts\"\n",
    "]\n",
    "```\n",
    "\n",
    "**Warning:** Don't use only these words to classify, the model is much more sophisticated and considers **combinations and TF-IDF scores**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Conclusion:**\n",
    "\n",
    "Coefficients reveal the model learned subtle patterns:\n",
    "- Detects **sarcasm** (positive words used ironically)\n",
    "- Identifies **discriminatory contexts** (neutral words in misuse)\n",
    "- Captures **specific meme culture**\n",
    "\n",
    "This explains why the model achieves 78% F1-score: it doesn't just look for obvious offensive words, but complex contextual patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb765a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: SOMETIMES I WISH I COULD AFFORD A HOOKER FOR AN ENTIRE NIGHT ONLY GIVE HER DECENT CLOTHING, TAKE HER TO A NICE RESTAURANT AND PAY HER A NIGHT AT A HOTEL FOR HER TO SLEEP COMFORTABLY, ALL SO SHE COULD HAVE A NICE NIGHT AMIDST ALL THE OTHER HARD ONES imgflip.com\n",
      "True: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: am \"Karens\" have had enough of being called \"Karens\" uch the actual photo PEOPLE, SOCIAL ISSUES 2 HOURS AGO UK Journalist Says Calling Women \"Karen\" Is Sexist Okay,um, Count me in as \"Who cares?\n",
      "True: 1\n",
      "Predicted: 0\n",
      "\n",
      "Text: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\n",
      "True: 1\n",
      "Predicted: 0\n",
      "\n",
      "Text: when your babysitter says Go to your room and youre like Damn ma you nasty but ok Lets do this SS @smh\n",
      "True: 1\n",
      "Predicted: 0\n",
      "\n",
      "Text: SPEAK UP FOR YOURSELF #SAY NO TO RAPE\n",
      "True: 0\n",
      "Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "misclassified = X_test[y_test != y_pred_tfidf]\n",
    "\n",
    "for i in misclassified.head(5).index:\n",
    "    print(\"\\nText:\", X_test[i])\n",
    "    print(\"True:\", y_test[i])\n",
    "    print(\"Predicted:\", y_pred_tfidf[list(X_test.index).index(i)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb102c11",
   "metadata": {},
   "source": [
    "### Explanation: Misclassified Cases Analysis - Model Errors\n",
    "\n",
    "**What does this cell do?**\n",
    "\n",
    "Examines **specific examples** where the model made mistakes to understand its **limitations** and possible **improvements**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Code explained:**\n",
    "\n",
    "```python\n",
    "misclassified_mask = y_test != y_pred_tfidf  # Boolean mask for incorrect predictions\n",
    "misclassified_indices = y_test[misclassified_mask].head(5).index  # Get first 5 error indices\n",
    "```\n",
    "\n",
    "Selects only documents where:\n",
    "- `y_test` (real label) ≠ `y_pred_tfidf` (prediction)\n",
    "\n",
    "Then displays the first 5 misclassified examples with their true and predicted labels.\n",
    "\n",
    "---\n",
    "\n",
    "#### **REAL examples of model errors:**\n",
    "\n",
    "---\n",
    "\n",
    "#### **ERROR #1: False Positive (predicted misogynous, but is NOT)**\n",
    "\n",
    "**Text:**\n",
    "```\n",
    "\"SOMETIMES I WISH I COULD AFFORD A HOOKER FOR AN ENTIRE NIGHT \n",
    "ONLY GIVE HER DECENT CLOTHING, TAKE HER TO A NICE RESTAURANT \n",
    "AND PAY HER A NIGHT AT A HOTEL FOR HER TO SLEEP COMFORTABLY, \n",
    "ALL SO SHE COULD HAVE A NICE NIGHT AMIDST ALL THE OTHER HARD ONES\"\n",
    "```\n",
    "\n",
    "**Real label:** 0 (NOT misogynous)  \n",
    "**Prediction:** 1 (misogynous)  \n",
    "**Status:** FALSE POSITIVE\n",
    "\n",
    "**Why did the model make a mistake?**\n",
    "\n",
    "**Detected keywords:**\n",
    "- **\"hooker\"** → High TF-IDF, strongly associated with misogynous content\n",
    "- Model does NOT understand **empathetic context**\n",
    "\n",
    "**Real context:**\n",
    "- Text expresses **empathy** and **humanization** of sex workers\n",
    "- Recognizes their humanity and dignity\n",
    "- **Intention**: Positive, anti-objectification\n",
    "\n",
    "**Model limitation:**\n",
    "- **Bag-of-words does not capture intention**\n",
    "- Presence of \"hooker\" triggers misogynous classification\n",
    "- Does NOT understand that **tone** is empathetic\n",
    "- Would need sentiment analysis or deeper contextual understanding\n",
    "\n",
    "**How to improve:**\n",
    "- Contextual language models (BERT, GPT)\n",
    "- Sentiment polarity analysis\n",
    "- Consider complete phrases (\"give her\", \"nice restaurant\")\n",
    "\n",
    "---\n",
    "\n",
    "#### **ERROR #2: False Negative (predicted NON-misogynous, but IS)**\n",
    "\n",
    "**Text:**\n",
    "```\n",
    "\"am \"Karens\" have had enough of being called \"Karens\" \n",
    "uch the actual photo PEOPLE, SOCIAL ISSUES 2 HOURS AGO \n",
    "UK Journalist Says Calling Women \"Karen\" Is Sexist \n",
    "Okay,um, Count me in as \"Who cares?\"\n",
    "```\n",
    "\n",
    "**Real label:** 1 (misogynous)  \n",
    "**Prediction:** 0 (NOT misogynous)  \n",
    "**Status:** FALSE NEGATIVE\n",
    "\n",
    "**Why did the model make a mistake?**\n",
    "\n",
    "**Context:**\n",
    "- Mocks women who denounce sexism\n",
    "- \"Who cares?\" minimizes legitimate discrimination concerns\n",
    "- **Subtle misogyny**: Does not use explicitly offensive words\n",
    "\n",
    "**Present words:**\n",
    "- \"sexist\", \"women\", \"journalist\" → Apparently neutral or even progressive\n",
    "- NO obviously misogynous keywords\n",
    "\n",
    "**Model limitation:**\n",
    "- **Does not detect second-level sarcasm**\n",
    "- Words individually seem feminist (\"sexist\", \"women\")\n",
    "- Needs to understand that **minimizing complaints** of sexism is problematic\n",
    "\n",
    "**How to improve:**\n",
    "- Detect minimization patterns (\"who cares\", \"okay um\")\n",
    "- Stance analysis (position toward a topic)\n",
    "- Understand multi-level irony\n",
    "\n",
    "---\n",
    "\n",
    "#### **ERROR #3: False Negative**\n",
    "\n",
    "**Text:**\n",
    "```\n",
    "\"When your mama don't change yo diaper for 19 years\"\n",
    "```\n",
    "\n",
    "**Real label:** 1 (misogynous)  \n",
    "**Prediction:** 0 (NOT misogynous)  \n",
    "**Status:** FALSE NEGATIVE\n",
    "\n",
    "**Why did the model make a mistake?**\n",
    "\n",
    "**Implicit context:**\n",
    "- Assumes childcare is mother's exclusive responsibility\n",
    "- Reinforces stereotyped gender roles\n",
    "- **Cultural/implicit misogyny**\n",
    "\n",
    "**Words:**\n",
    "- \"mama\", \"diaper\", \"change\" → Neutral per se\n",
    "- No explicitly offensive terms\n",
    "\n",
    "**Model limitation:**\n",
    "- **Does not detect implicit gender stereotypes**\n",
    "- Requires understanding cultural norms\n",
    "- Bag-of-words does not capture underlying assumptions\n",
    "\n",
    "**How to improve:**\n",
    "- Train with \"implicit misogyny\" annotations\n",
    "- Stereotype knowledge base\n",
    "- Models that understand social roles\n",
    "\n",
    "---\n",
    "\n",
    "#### **ERROR #4: False Negative**\n",
    "\n",
    "**Text:**\n",
    "```\n",
    "\"when your babysitter says Go to your room and youre like \n",
    "Damn ma you nasty but ok Lets do this\"\n",
    "```\n",
    "\n",
    "**Real label:** 1 (misogynous)  \n",
    "**Prediction:** 0 (NOT misogynous)  \n",
    "**Status:** FALSE NEGATIVE\n",
    "\n",
    "**Why did the model make a mistake?**\n",
    "\n",
    "**Context:**\n",
    "- Sexual insinuation toward a babysitter\n",
    "- \"you nasty but ok Lets do this\" → Sexual connotation\n",
    "- Objectification of a caregiver (position of trust)\n",
    "\n",
    "**Words:**\n",
    "- \"nasty\", \"room\", \"babysitter\" → Individually neutral\n",
    "- The **combination** creates sexual meaning\n",
    "\n",
    "**Model limitation:**\n",
    "- **Does not capture subtle sexual implications**\n",
    "- Unigrams/bigrams not sufficient for this context\n",
    "- Needs to understand power dynamics and insinuations\n",
    "\n",
    "---\n",
    "\n",
    "#### **ERROR #5: False Positive**\n",
    "\n",
    "**Text:**\n",
    "```\n",
    "\"SPEAK UP FOR YOURSELF #SAY NO TO RAPE\"\n",
    "```\n",
    "\n",
    "**Real label:** 0 (NOT misogynous)  \n",
    "**Prediction:** 1 (misogynous)  \n",
    "**Status:** FALSE POSITIVE\n",
    "\n",
    "**Why did the model make a mistake?**\n",
    "\n",
    "**Context:**\n",
    "- **Anti-rape** message, empowerment\n",
    "- Clearly feminist and pro-women\n",
    "\n",
    "**Keywords:**\n",
    "- **\"RAPE\"** → Word strongly associated with problematic content\n",
    "- Classifier does not distinguish **mention** vs **promotion**\n",
    "\n",
    "**Model limitation:**\n",
    "- **Does not differentiate between talking ABOUT a problem vs CAUSING the problem**\n",
    "- \"rape\" triggers classification although message is preventive\n",
    "- Common problem in content moderation\n",
    "\n",
    "**How to improve:**\n",
    "- Stance analysis: FOR vs AGAINST\n",
    "- Detect activist hashtags (#SayNo, #SpeakUp)\n",
    "- Understand advocacy/denunciation contexts\n",
    "\n",
    "---\n",
    "\n",
    "#### **General error patterns:**\n",
    "\n",
    "**False Positives (incorrectly predicts misogynous):**\n",
    "1. **Keywords without context**: \"hooker\", \"rape\" trigger classification\n",
    "2. **Feminist sarcasm/irony**: Criticisms of misogyny misinterpreted\n",
    "3. **Descriptive mentions**: Talking ABOUT misogyny ≠ BEING misogynous\n",
    "\n",
    "**False Negatives (does not detect real misogyny):**\n",
    "1. **Implicit/subtle misogyny**: Stereotypes without offensive words\n",
    "2. **Minimization**: Mocking sexism complaints\n",
    "3. **Sexual insinuations**: Indirect objectification\n",
    "4. **Complex irony**: Multiple interpretation levels\n",
    "\n",
    "---\n",
    "\n",
    "#### **Fundamental limitations of TF-IDF + Logistic Regression approach:**\n",
    "\n",
    "Does not understand deep semantic context\n",
    "Does not detect sarcasm/irony\n",
    "Does not differentiate mention vs promotion\n",
    "Does not capture implicit stereotypes\n",
    "Bag-of-words ignores order and structure\n",
    "Has no world knowledge\n",
    "\n",
    "---\n",
    "\n",
    "#### **Recommendations to improve:**\n",
    "\n",
    "**Short term (with TF-IDF):**\n",
    "1. **More training data** with subtle misogyny annotations\n",
    "2. **Trigrams/quatrigrams** for longer phrases\n",
    "3. **Include hashtag context** (#SayNo → anti-misogyny signal)\n",
    "4. **Class weights** to penalize FN more than FP\n",
    "\n",
    "**Long term (new architectures):**\n",
    "1. **Transformers (BERT, RoBERTa)**: Understand bidirectional context\n",
    "2. **Multimodal analysis**: Consider image + text\n",
    "3. **Transfer learning**: Pre-training on hate speech corpus\n",
    "4. **Ensemble methods**: Combine multiple models\n",
    "\n",
    "---\n",
    "\n",
    "#### **Conclusion:**\n",
    "\n",
    "Error analysis reveals that **TF-IDF captures obvious lexical patterns** but **fails in subtle cases** requiring:\n",
    "- Deep contextual understanding\n",
    "- Irony and sarcasm detection\n",
    "- Knowledge of social dynamics\n",
    "- Inference of implications\n",
    "\n",
    "These 5 examples represent the **324 total errors** (21.6%) and show directions where the model needs improvement to achieve human-level performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries_env (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
